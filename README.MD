
# ğŸš€ Load Balancer Project â€“ NGINX + Docker + Round Robin + Canary + Weighted Rollout

This project demonstrates **real-world load balancing behavior** using **NGINX**, **Docker**, and **multiple backend microservices**.  
You will learn how modern systems gradually roll out features, balance traffic efficiently, and prevent outages using **traffic weights, canary releases, sticky routing, and circuit-breaker principles.**

---

## ğŸ”¥ Features Implemented

| Functionality | Status |
|---|---|
| Round Robin Load Balancing | âœ” |
| Weighted Load Balancing (90/10 Canary) | âœ” |
| Sticky Session Routing | âœ” |
| Canary Release Simulation | âœ” |
| Circuit Breaker Failure Handling | âœ” |
| Auto Canary Monitoring Script | âœ” |

---

## ğŸ“‚ Project Structure

LoadBalancer-Project/
â”‚
â”œâ”€â”€ backend1/               # Stable Version (Blue)
â”‚   â”œâ”€â”€ server.js
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ backend2/               # Canary Version (Green)
â”‚   â”œâ”€â”€ server.js
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ nginx.conf              # NGINX Load Balancer Configuration
â”œâ”€â”€ docker-compose.yaml     # Runs all services
â”œâ”€â”€ canary-monitor.js       # Health Test Script
â””â”€â”€ README.md               # Documentation

---

## ğŸ–¥ Backend Services

### backend1/server.js

 const express = require("express");
 const app = express();
 app.get("/", (req, res) => res.send("âš¡ Backend 1 - Stable OK"));
 app.listen(3001, () => console.log("Backend1 running on port 3001"));

---

### backend2/server.js

 const express = require("express");
 const app = express();
 app.get("/", (req, res) => res.send("ğŸŒ± Backend 2 - Canary OK"));
 app.listen(3002, () => console.log("Backend2 running on port 3002"));

---

## ğŸ³ Docker Configuration

### Shared Dockerfile (inside each backend folder)

 FROM node:18
 WORKDIR /app
 COPY server.js .
 RUN npm install express
 EXPOSE 3001   # backend2 uses 3002
 CMD ["node","server.js"]

---

## âš™ docker-compose.yaml

services:
  backend1:
    build: ./backend1
    ports: ["3001:3001"]

  backend2:
    build: ./backend2
    ports: ["3002:3002"]

  nginx:
    image: nginx
    ports: ["8080:8080"]
    depends_on: [backend1, backend2]
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro

Run project:

docker-compose up --build

Visit:

http://localhost:8080

---

## ğŸŒ NGINX Load Balancer (90% Blue / 10% Green)

http {
    upstream backend_servers {
        server backend1:3001 weight=9;   # 90%
        server backend2:3002 weight=1;   # 10% Canary
    }

    server {
        listen 8080;
        location / {
            proxy_pass http://backend_servers;
        }
    }
}

---

## ğŸ” Testing Load Balancer

for i in {1..20}; do curl -s localhost:8080; echo ""; done

Expected Output:

âš¡ Backend1
âš¡ Backend1
ğŸŒ± Backend2   â† Canary Hit
âš¡ Backend1
ğŸŒ± Backend2

---

## ğŸ“Œ Sticky Sessions (IP Hash)

upstream backend_servers {
    ip_hash;
    server backend1:3001;
    server backend2:3002;
}

---

## ğŸ›‘ Circuit Breaker Behavior Test

docker stop <backend2-container>
System self-heals using only backend1.

---

## ğŸ“Š Canary Monitoring Script

const { execSync } = require("child_process");
let success=0, fail=0;

for(let i=0;i<200;i++){
  try{ execSync("curl -s localhost:8080"); success++; }
  catch{ fail++; }
}

console.log(`Total: ${success+fail} Success: ${success} Failures: ${fail}`);

Run:

node canary-monitor.js

---

## ğŸ¯ Summary

| Concept | Status |
|---|---|
| Round Robin LB | âœ” |
| Weighted Canary | âœ” |
| Sticky Sessions | âœ” |
| Circuit Breaker | âœ” |
| Real Deployment Simulation | âœ” |

---
